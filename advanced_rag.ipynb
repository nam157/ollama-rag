{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b68a2fa-c33a-4c15-a81c-655ed1e21f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED     \n",
      "deepseek-r1:32b            38056bbcbb2d    19 GB     13 days ago     \n",
      "qwen2.5-coder:32b          4bd6cbf2d094    19 GB     2 weeks ago     \n",
      "llama3.2:3b                a80c4f17acd5    2.0 GB    3 weeks ago     \n",
      "mistral:latest             f974a74358d6    4.1 GB    4 weeks ago     \n",
      "deepseek-r1:14b            ea35dfe18182    9.0 GB    4 weeks ago     \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    5 weeks ago     \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    6 weeks ago     \n",
      "llama3.2-vision:latest     085a1fdae525    7.9 GB    6 weeks ago     \n",
      "llama3:latest              365c0bd3c000    4.7 GB    7 weeks ago     \n",
      "llama2:latest              78e26419b446    3.8 GB    2 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c1fb79-f7cf-477b-8a15-bb9adfbc4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import HnswConfig, HnswConfigDiff\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance, PointStruct\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable.passthrough import RunnablePassthrough\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "import uuid\n",
    "\n",
    "# Initial variables\n",
    "file = \"/home/namnh1/rag-llm-chatbot/Qu·∫£n l√Ω m√¥ h√¨nh AI camera.pdf\"\n",
    "chunk_size = 500\n",
    "chunk_overlap = 100\n",
    "collection_name = \"ai-camera-deepseek\"\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatOllama(\n",
    "        model=\"deepseek-r1:14b\",\n",
    "        temperature=0,\n",
    "        streaming=True\n",
    "    )\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")\n",
    "loader = PyMuPDFLoader(file)\n",
    "documents = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, \n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "        )\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d6baad7-513b-42dc-8458-17d94507b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010a0789-f5ce-458b-a8d8-e45c50a824b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "class Qdrant:\n",
    "    def __init__(self, host = \"10.100.140.54\", port = 6333):\n",
    "        self.client = QdrantClient(host= host, port= port)\n",
    "        self.reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "    def create_collection(self, collection_name):\n",
    "        existing_collections = [col.name for col in self.client.get_collections().collections]\n",
    "        if collection_name not in existing_collections:\n",
    "            self.client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(\n",
    "                    size=len(embeddings.embed_query(\"sample text\")), \n",
    "                    distance=Distance.COSINE\n",
    "                ),\n",
    "                hnsw_config=HnswConfigDiff(\n",
    "                    m=16,                    # Number of connections per node\n",
    "                    ef_construct=100,       # Higher value = better recall\n",
    "                    full_scan_threshold=10000  # Adding the missing required field\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "    def insert_documents(self, collection_name: str, doc_chunks: List, embeddings):\n",
    "        vectors = [\n",
    "            embeddings.embed_query(chunk.page_content) for chunk in doc_chunks\n",
    "        ]\n",
    "        payloads = [\n",
    "            {\"id\": str(uuid.uuid4()), \"text\": chunk.page_content} for chunk in doc_chunks\n",
    "        ]\n",
    "        \n",
    "        points = [\n",
    "            PointStruct(id=payload[\"id\"], vector=vectors[i], payload=payload) for i, payload in enumerate(payloads)\n",
    "        ]\n",
    "\n",
    "        # S·ª≠ d·ª•ng upsert thay v√¨ upload_collection\n",
    "        self.client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "\n",
    "\n",
    "    def search_database(self, collection_name, question, embeddings, limit=3):\n",
    "        query_vector = embeddings.embed_query(question)\n",
    "        search_result = self.client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            query=query_vector,\n",
    "            limit=limit\n",
    "        ).points\n",
    "        if not search_result:\n",
    "            return \"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£.\"\n",
    "        try:\n",
    "            text_result = \"\\n\\n\".join(hit.payload['text'] for hit in search_result)\n",
    "            return text_result\n",
    "        except KeyError as e:\n",
    "            return \"L·ªói: C·∫•u tr√∫c payload kh√¥ng h·ª£p l·ªá.\"\n",
    "        except Exception as e:\n",
    "            return \"L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω k·∫øt qu·∫£ t√¨m ki·∫øm.\"\n",
    "\n",
    "    def rerank_documents(self, question: str, documents: List[str], top_k: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Rerank a list of documents based on relevance to the question using CrossEncoder.\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "        \n",
    "        rerank_inputs = [[question, doc] for doc in documents]\n",
    "        scores = self.reranker.predict(rerank_inputs, batch_size=32)\n",
    "        sorted_pairs = sorted(zip(scores, documents), reverse=True)\n",
    "        return [doc for _, doc in sorted_pairs][:top_k]\n",
    "    \n",
    "    def search_database_fusion_bm250(self, collection_name, question, embeddings, doc_chunks, limit=5):\n",
    "        # üîç BM25 Search\n",
    "        texts = [doc.page_content for doc in doc_chunks]  # L·∫•y to√†n b·ªô vƒÉn b·∫£n ƒë√£ index\n",
    "        tokenized_corpus = [text.split() for text in texts]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        bm25_scores = bm25.get_scores(question.split())\n",
    "    \n",
    "        top_bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:limit]\n",
    "        top_bm25_results = [texts[i] for i in top_bm25_indices]\n",
    "    \n",
    "        # üîç Vector Search\n",
    "        query_vector = embeddings.embed_query(question)\n",
    "        search_result = self.client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=limit\n",
    "        )\n",
    "    \n",
    "        # üåÄ Fusion Search (K·∫øt h·ª£p BM25 + Vector Search)\n",
    "        fusion_results = top_bm25_results + [hit.payload['text'] for hit in search_result if 'text' in hit.payload]\n",
    "        fusion_results = list(set(fusion_results))  # Lo·∫°i b·ªè k·∫øt qu·∫£ tr√πng l·∫∑p\n",
    "\n",
    "        # Rerank combined results\n",
    "        reranked_docs = self.rerank_documents(question, fusion_results, top_k=limit)\n",
    "        \n",
    "        return \"\\n\\n\".join(fusion_results[:limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2f1d8c-93c1-462d-94a9-e0d8c628d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh. T√™n b·∫°n l√† DetNam. B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o t√†i li·ªáu/tri th·ª©c ƒë∆∞·ª£c cung c·∫•p t·ª´ ngu·ªìn b√™n ngo√†i. D·ª±a tr√™n th√¥ng tin ƒë√≥, h√£y tr·∫£ l·ªùi theo c√°ch ch√≠nh x√°c, t·ª± nhi√™n v√† h·ªØu √≠ch nh·∫•t.\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Tr·∫£ l·ªùi c√¢u h·ªèi: {question}  \n",
    "- D·ª±a tr√™n th√¥ng tin t·ª´ ngu·ªìn d·ªØ li·ªáu, t·ªïng h·ª£p v√† tr√¨nh b√†y c√¢u tr·∫£ l·ªùi. N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, b√°o r√µ v√† b·ªï sung ki·∫øn th·ª©c chung n·∫øu ph√π h·ª£p.\n",
    "- N·∫øu c√¢u h·ªèi kh√¥ng n·∫±m trong t√†i li·ªáu v√† kh√¥ng li√™n quan t·ªõi t√†i li·ªáu, h√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i ƒë·ªÉ tr·∫£ l·ªùi.\n",
    "Retrieved context:\n",
    "{context}\n",
    "\n",
    "[Details]  \n",
    "- S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, ng·∫Øn g·ªçn.  \n",
    "- ƒê·ªãnh d·∫°ng: [T√≥m t·∫Øt] - [Gi·∫£i th√≠ch]- [V√≠ d·ª• m·∫´u]- [Flow chart] - [K·∫øt lu·∫≠n].\n",
    "- ƒê∆∞a th√™m g·ª£i √Ω c√¢u h·ªèi ti·∫øp theo\n",
    "\n",
    "[Example]\n",
    "- Xin ch√†o/hi/hello -> t√¥i t√™n DetNam, tr·ª£ l√Ω th√¥ng minh, t√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n ƒë√¢y.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e501864b-d45d-42a6-aebc-f3be5eec416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chain(llm, qdrant_client, collection_name, embeddings, question, history):\n",
    "    retrieved_context = qdrant_client.search_database_fusion_bm250(collection_name, question, embeddings, docs)\n",
    "    \n",
    "    pipeline = (\n",
    "        RunnablePassthrough()\n",
    "        | {\"history\": lambda x: history, \"question\": lambda x: question, \"context\": lambda x: retrieved_context}\n",
    "        | ChatPromptTemplate.from_template(prompt_template)\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = pipeline.invoke({})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e4b6b-a2af-4187-b72a-10c386ec585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi v√†o ƒë√¢y nh√©:  hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I'm trying to figure out how to respond to the user's message. They just said \"hi,\" which is a common greeting. From the context provided, it looks like DetNam is an AI assistant designed to help with various tasks, especially related to camera management and data analysis using tools like Hikvision cameras, Jetson Nano, and cloud storage solutions.\n",
      "\n",
      "First, I need to acknowledge their greeting in a friendly manner. Then, I should offer assistance based on the capabilities outlined in the provided context. The user might be looking for help with setting up camera systems, data analysis, or integrating different components like NVRs, port forwarding, or choosing appropriate databases.\n",
      "\n",
      "I should structure my response using the specified format: [T√≥m t·∫Øt] - [Gi·∫£i th√≠ch]- [V√≠ d·ª• m·∫´u]- [Flow chart] - [K·∫øt lu·∫≠n]. However, since I'm just outlining the thought process, I'll focus on how to create a helpful and structured reply without markdown.\n",
      "\n",
      "I need to make sure my response is clear, concise, and covers all necessary points. Also, after providing the information, I should include a follow-up question to engage the user further, encouraging them to specify their needs or ask more detailed questions.\n",
      "</think>\n",
      "\n",
      "[DetNam]  \n",
      "- T√≥m t·∫Øt: Xin ch√†o! T√¥i l√† DetNam, m·ªôt tr·ª£ l√Ω AI c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi c√°c h·ªá th·ªëng camera v√† ph√¢n t√≠ch d·ªØ li·ªáu.  \n",
      "- Gi·∫£i th√≠ch: T√¥i c√≥ ki·∫øn th·ª©c v·ªÅ ph·∫ßn m·ªÅm qu·∫£n l√Ω camera nh∆∞ Hik Central Professional, c≈©ng nh∆∞ vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu tr√™n Jetson Nano v√† l∆∞u tr·ªØ d·ªØ li·ªáu b·∫±ng MySQL, MongoDB, ho·∫∑c cloud storage.  \n",
      "- V√≠ d·ª• m·∫´u: B·∫°n ƒëang mu·ªën l·∫Øp ƒë·∫∑t camera gi√°m s√°t? T√¥i c√≥ th·ªÉ h∆∞·ªõng d·∫´n b·∫°n c√°ch k·∫øt n·ªëi camera v·ªõi NVR v√† c·∫•u h√¨nh port forwarding ƒë·ªÉ truy c·∫≠p t·ª´ xa.  \n",
      "- Flow chart: Greet User ‚Üí Offer Assistance ‚Üí Await Specific Request  \n",
      "- K·∫øt lu·∫≠n: T√¥i s·∫µn s√†ng gi√∫p ƒë·ª°! B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ v·ªÅ h·ªá th·ªëng camera ho·∫∑c ph√¢n t√≠ch d·ªØ li·ªáu?  \n",
      "\n",
      "G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo: B·∫°n ƒëang g·∫∑p kh√≥ khƒÉn g√¨ trong vi·ªác l·∫Øp ƒë·∫∑t camera ho·∫∑c x·ª≠ l√Ω d·ªØ li·ªáu?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  lo·∫°i camera n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ai camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I need to figure out what type of camera is used in AI cameras. From the context provided, it mentions Hikvision AI Cameras. These are specifically noted for their integration with AI capabilities, allowing them to perform image analysis directly on the device.\n",
      "\n",
      "Let me break this down. The user is asking about the camera type used in AI systems, so I should focus on the models or brands that incorporate AI features. Hikvision is a well-known brand in security cameras, and they have specific AI-enabled models. These cameras likely use advanced sensors and processing units to handle tasks like facial recognition, object detection, etc.\n",
      "\n",
      "I should also consider mentioning how these cameras integrate with other systems, such as NVRs (Network Video Recorders) for storage and management. Additionally, the use of Jetson Nano by Nvidia is mentioned for on-device processing, which suggests that edge computing plays a role in AI camera functionality.\n",
      "\n",
      "To structure my answer, I'll start by identifying Hikvision AI Cameras as the primary type. Then, explain their features, maybe give an example like the DS-XX series (though specific models aren't provided). Finally, I can outline how these cameras fit into a broader system, possibly including flowcharts or diagrams to illustrate the integration process.\n",
      "\n",
      "I should also ensure that my explanation is clear and concise, avoiding too much technical jargon unless necessary. The user might be looking for a basic understanding rather than detailed specifications.\n",
      "\n",
      "Lastly, I'll conclude by summarizing the key points and perhaps suggest follow-up questions if they need more details on specific models or functionalities.\n",
      "</think>\n",
      "\n",
      "**Lo·∫°i camera n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng trong AI camera?**\n",
      "\n",
      "- **T√≥m t·∫Øt**: Camera AI th∆∞·ªùng s·ª≠ d·ª•ng c√°c d√≤ng camera Hikvision t√≠ch h·ª£p AI.\n",
      "  \n",
      "- **Gi·∫£i th√≠ch**: Camera AI l√† nh·ªØng thi·∫øt b·ªã c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch v√† nh·∫≠n di·ªán h√¨nh ·∫£nh tr·ª±c ti·∫øp. Hikvision cung c·∫•p c√°c model camera AI n√†y, ƒë∆∞·ª£c trang b·ªã chipset v√† ph·∫ßn m·ªÅm ƒë·ªÉ x·ª≠ l√Ω c√°c t√°c v·ª• nh∆∞ nh·∫≠n di·ªán khu√¥n m·∫∑t, ki·ªÉm tra an ninh, v.v.\n",
      "\n",
      "- **V√≠ d·ª• m·∫´u**: M·ªôt s·ªë model camera AI c·ªßa Hikvision c√≥ th·ªÉ bao g·ªìm d√≤ng DS-XX series, m·∫∑c d√π chi ti·∫øt c·ª• th·ªÉ v·ªÅÂûãÂè∑ kh√¥ng ƒë∆∞·ª£c cung c·∫•p trong d·ªØ li·ªáu.\n",
      "\n",
      "- **Flow chart**:\n",
      "  1. Camera AI (Hikvision) thu nh·∫≠n h√¨nh ·∫£nh.\n",
      "  2. X·ª≠ l√Ω d·ªØ li·ªáu b·∫±ng ph·∫ßn m·ªÅm AI onboard ho·∫∑c k·∫øt n·ªëi v·ªõi h·ªá th·ªëng x·ª≠ l√Ω trung t√¢m.\n",
      "  3. K·∫øt qu·∫£ ph√¢n t√≠ch ƒë∆∞·ª£c hi·ªÉn th·ªã v√† l∆∞u tr·ªØ, n·∫øu c·∫ßn.\n",
      "\n",
      "- **K·∫øt lu·∫≠n**: Camera AI ch·ªß y·∫øu s·ª≠ d·ª•ng c√°c model c·ªßa Hikvision, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ th·ª±c hi·ªán ph√¢n t√≠ch v√† nh·∫≠n di·ªán h√¨nh ·∫£nh ngay t·∫°i thi·∫øt b·ªã ho·∫∑c k·∫øt n·ªëi v·ªõi h·ªá th·ªëng qu·∫£n l√Ω t·∫≠p trung.\n",
      "\n",
      "**G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo**: B·∫°n mu·ªën bi·∫øt th√™m v·ªÅ c√°ch camera AI n√†y ho·∫°t ƒë·ªông c·ª• th·ªÉ nh∆∞ th·∫ø n√†o kh√¥ng?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  Ph∆∞∆°ng th·ª©c k·∫øt n·ªëi ƒë∆∞·ª£c s·ª≠ d·ª•ng trong n√†y l√† g√¨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I need to figure out what connection method is being used here. The user mentioned \"ph∆∞∆°ng th·ª©c k·∫øt n·ªëi ƒë∆∞·ª£c s·ª≠ d·ª•ng trong n√†y l√† g√¨,\" which translates to \"what connection method is used here.\" Looking at the context provided, it's about a system involving Jetson Nano devices, a central machine, data storage, and security measures.\n",
      "\n",
      "First, I'll go through each section of the retrieved context to identify any connection methods. Under the Machine Tr·∫°m Jetson Nano, they mention SQLite or Local JSON Files for temporary storage. That's more about data storage rather than connections.\n",
      "\n",
      "Moving on to M√°y T·ªïng H·ª£p (Central Machine), it talks about relational databases like MySQL or PostgreSQL and NoSQL databases like MongoDB. Again, these are about data storage structures, not connection methods between devices or systems.\n",
      "\n",
      "In the section about C√¥ng c·ª• Ph√¢n t√≠ch v√† K·∫øt n·ªëi (Analysis and Connection Tools), there's a mention of RESTful APIs using FastAPI on both the Jetson Nano and central machine. RESTful APIs are definitely a method for enabling communication between different parts of a system. Then, WebSocket is mentioned for real-time data updates, which is another protocol for establishing connections. MQTT is also listed as a protocol for connecting IoT devices, so that's another connection method.\n",
      "\n",
      "Looking further into B·∫£o m·∫≠t v√† An to√†n (Security and Safety), they talk about HTTPS, SSL/TLS for data transmission encryption, OAuth 2.0, JWT for authentication. These are more about securing the connections rather than the methods themselves.\n",
      "\n",
      "In the section on C·∫•u h√¨nh ƒê·∫ßu ghi NVR v√† Port Forwarding (NVR Configuration and Port Forwarding), it mentions port forwarding to allow remote access to the NVR. This involves redirecting ports through a router, which is a networking technique for establishing external connections.\n",
      "\n",
      "So putting this together, the connection methods used include RESTful APIs, WebSocket, MQTT, HTTPS/SSL/TLS, OAuth 2.0/JWT, and port forwarding. Each of these serves different purposes in enabling communication between devices, securing data transmission, and allowing remote access.\n",
      "\n",
      "I should structure the answer to first list each method, then explain what they are, provide examples, maybe a flowchart if possible, and conclude with how they work together. Also, I can suggest the next question about advantages or disadvantages of these methods.\n",
      "</think>\n",
      "\n",
      "**Ph∆∞∆°ng th·ª©c k·∫øt n·ªëi ƒë∆∞·ª£c s·ª≠ d·ª•ng trong h·ªá th·ªëng n√†y l√† g√¨?**\n",
      "\n",
      "- **T√≥m t·∫Øt:** H·ªá th·ªëng n√†y s·ª≠ d·ª•ng c√°c ph∆∞∆°ng th·ª©c k·∫øt n·ªëi RESTful API, WebSocket, MQTT, HTTPS/SSL/TLS, OAuth 2.0/JWT, v√† Port Forwarding.\n",
      "\n",
      "- **Gi·∫£i th√≠ch:**\n",
      "  - **RESTful APIs:** L√† giao di·ªán ng∆∞·ªùi d√πng ch∆∞∆°ng tr√¨nh (API) cho ph√©p truy·ªÅn d·ªØ li·ªáu qua HTTP.\n",
      "  - **WebSocket:** L√†ÂçèËÆÆ cho ph√©p k·∫øt n·ªëi hai-way trong th·ªùi gian th·ª±c.\n",
      "  - **MQTT:** L√† protocol nh·∫π nh√†ng, ph√π h·ª£p cho IoT.\n",
      "  - **HTTPS/SSL/TLS:** B·∫£o m·∫≠t d·ªØ li·ªáuÂú®ÁΩëÁªú.\n",
      "  - **OAuth 2.0/JWT:** X√°c th·ª±c v√† ·ªßy quy·ªÅn an to√†n.\n",
      "  - **Port Forwarding:**.redirect ports ƒë·ªÉ truy c·∫≠p t·ª´ xa.\n",
      "\n",
      "- **V√≠ d·ª• m·∫´u:**\n",
      "  - RESTful API ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ g·ª≠i d·ªØ li·ªáu t·ª´ Jetson Nano ƒë·∫øn m√°y trung t√¢m.\n",
      "  - WebSocket c·∫≠p nh·∫≠t d·ªØ li·ªáu th·ªùi gian th·ª±c gi·ªØa c√°c thi·∫øt b·ªã.\n",
      "  - MQTT k·∫øt n·ªëi v·ªõi camera IoT qua m·∫°ng.\n",
      "  - HTTPS ƒë·∫£m b·∫£o truy·ªÅn d·ªØ li·ªáu an to√†n.\n",
      "\n",
      "- **Flowchart:** (M√¥ t·∫£ b·∫±ng ch·ªØ)\n",
      "  1. D·ªØ li·ªáu t·ª´ Jetson Nano g·ª≠i ƒë·∫øn m√°y trung t√¢m qua RESTful API.\n",
      "  2. WebSocket c·∫≠p nh·∫≠t d·ªØ li·ªáu th·ªùi gian th·ª±c.\n",
      "  3. MQTT x·ª≠ l√Ω k·∫øt n·ªëi IoT.\n",
      "  4. B·∫£o m·∫≠t v·ªõi HTTPS v√† x√°c th·ª±c OAuth 2.0/JWT.\n",
      "  5. Port Forwarding cho ph√©p truy c·∫≠p t·ª´ xa v√†o NVR.\n",
      "\n",
      "- **K·∫øt lu·∫≠n:** C√°c ph∆∞∆°ng th·ª©c n√†y gi√∫p h·ªá th·ªëng truy·ªÅn d·ªØ li·ªáu hi·ªáu qu·∫£, an to√†n, v√† cho ph√©p k·∫øt n·ªëi t·ª´ xa.\n",
      "\n",
      "**G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo:**\n",
      "- B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch ∆∞u nh∆∞·ª£c ƒëi·ªÉm c·ªßa t·ª´ng ph∆∞∆°ng th·ª©c k·∫øt n·ªëi ƒë∆∞·ª£c s·ª≠ d·ª•ng kh√¥ng?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  nh·ªØng port n√†o c·∫ßn ƒë∆∞·ª£c nat trong ai camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I need to figure out which ports need to be NATed for an AI camera setup. From what I remember, NAT stands for Network Address Translation, and it's used to map public addresses to private ones, allowing devices on a local network to connect to the internet.\n",
      "\n",
      "Looking at the context provided, there's mention of port forwarding in relation to NVRs. It specifically lists ports 80 (HTTP), 443 (HTTPS), 8000 (Server), and 554 (RTSP). These are common ports used for various services like web traffic, secure connections, server access, and real-time streaming.\n",
      "\n",
      "I think the key here is that when setting up remote access to an NVR or AI camera system, these specific ports need to be forwarded through the router. This allows external devices to communicate with the internal network devices using those ports.\n",
      "\n",
      "So, the ports that need NATing would typically include 80, 443, 8000, and 554. Each of these serves a different purpose but is essential for full functionality when accessing the camera system remotely.\n",
      "\n",
      "I should also consider if there are any additional ports specific to AI cameras or Hikvision devices that might be required, but based on the given context, those four seem to cover the necessary ones.\n",
      "</think>\n",
      "\n",
      "**C√°c c·ªïng c·∫ßn NAT trong h·ªá th·ªëng AI camera:**\n",
      "\n",
      "- **80 (HTTP)**: ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ truy c·∫≠p giao di·ªán web c·ªßa NVR ho·∫∑c camera t·ª´ xa qua k·∫øt n·ªëi kh√¥ng m√£ h√≥a.\n",
      "  \n",
      "- **443 (HTTPS)**: S·ª≠ d·ª•ng cho k·∫øt n·ªëi an to√†n, m√£ h√≥a d·ªØ li·ªáu khi truy c·∫≠p t·ª´ xa.\n",
      "\n",
      "- **8000 (Server)**: C·ªïng n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c√°c d·ªãch v·ª• server c·ªßa NVR ho·∫∑c h·ªá th·ªëng camera AI.\n",
      "\n",
      "- **554 (RTSP)**: Quan tr·ªçng ƒë·ªÉ stream videoÂÆûÊó∂ streaming v√† ƒëi·ªÅu khi·ªÉn camera t·ª´ xa.\n",
      "\n",
      "**Gi·∫£i th√≠ch:** NAT c·∫ßn thi·∫øt ƒë·ªÉ c√°c c·ªïng n√†y c√≥ th·ªÉ ti·∫øp nh·∫≠n k·∫øt n·ªëi t·ª´ b√™n ngo√†i, cho ph√©p truy c·∫≠p v√† gi√°m s√°t camera t·ª´ xa m·ªôt c√°ch hi·ªáu qu·∫£.\n",
      "\n",
      "**V√≠ d·ª• m·∫´u:** Khi c·∫•u h√¨nh port forwarding tr√™n router, b·∫°n c·∫ßn ƒë·ªãnh tuy·∫øn c√°c c·ªïng 80, 443, 8000, v√† 554 ƒë·∫øn IP c·ªßa NVR trong m·∫°ng local.\n",
      "\n",
      "**K·∫øt lu·∫≠n:** B·ªën c·ªïng n√†y l√† c·∫ßn thi·∫øt ƒë·ªÉ ƒë·∫£m b·∫£o k·∫øt n·ªëi t·ª´ xa v·ªõi h·ªá th·ªëng camera AI, cho ph√©p gi√°m s√°t v√† qu·∫£n l√Ω hi·ªáu qu·∫£.\n",
      "\n",
      "**G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo:** B·∫°n c√≥ mu·ªën bi·∫øt th√™m v·ªÅ c√°ch c·∫•u h√¨nh NAT ho·∫∑c port forwarding c·ª• th·ªÉ kh√¥ng?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  Li·ªát k√™ c√°c module AI s·∫Ω tri·ªÉn khai \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I need to figure out how to list all the AI modules that will be deployed. Let me start by looking at the information provided.\n",
      "\n",
      "First, there's software and analysis tools mentioned. Hik Central Professional is a camera management software from Hikvision for monitoring, configuration, and adjustments. Then, on Jetson Nano, they're using data analysis which includes face recognition, gender and age detection, counting people, and nationality recognition. \n",
      "\n",
      "Next, monitoring tools like Grafana and Prometheus are used to keep track of the status of edge devices and aggregators. Logging is handled by ELK Stack for collecting, analyzing, and displaying logs. For remote management, they use TeamViewer and AnyDesk, and automated alerts via email or SMS when issues occur.\n",
      "\n",
      "In terms of deployment, they're using Google Cloud Storage or Synology NAS for long-term storage. APIs are created with FastAPI on edge devices and aggregators. WebSocket is used for real-time data updates, and MQTT connects IoT devices for lightweight data transmission.\n",
      "\n",
      "Security measures include data protection, though the specifics aren't detailed here. Configuration of NVRs involves connecting cameras, setting recording schedules, and enabling remote access. Port forwarding is set up in the router to allow external access to the NVR.\n",
      "\n",
      "The hardware setup includes edge devices like Jetson Nano for local processing tasks, especially deep learning models and image analysis. The aggregator is a more powerful server, possibly with an Nvidia GPU, handling data from multiple Jetson Nanos, storage, and complex analyses.\n",
      "\n",
      "Putting this all together, I can outline each module step by step.\n",
      "</think>\n",
      "\n",
      "**Danh s√°ch c√°c module AI s·∫Ω tri·ªÉn khai:**\n",
      "\n",
      "1. **Ph·∫ßn m·ªÅm Qu·∫£n l√Ω Camera (Hik Central Professional):**\n",
      "   - **T√≥m t·∫Øt:** Giao di·ªán qu·∫£n l√Ω camera t·ª´ Hikvision.\n",
      "   - **Gi·∫£i th√≠ch:** Cung c·∫•p gi√°m s√°t, c·∫•u h√¨nh v√† ƒëi·ªÅu ch·ªânh camera.\n",
      "   - **V√≠ d·ª• m·∫´u:** K·∫øt n·ªëi v√† gi√°m s√°t c√°c camera Hikvision.\n",
      "   - **Flow chart:** K·∫øt n·ªëi camera ‚Üí Gi√°m s√°t qua giao di·ªán ‚Üí ƒêi·ªÅu ch·ªânh th√¥ng s·ªë.\n",
      "\n",
      "2. **Ph√¢n t√≠ch D·ªØ li·ªáu tr√™n Jetson Nano:**\n",
      "   - **T√≥m t·∫Øt:** X·ª≠ l√Ω d·ªØ li·ªáu video b·∫±ng AI.\n",
      "   - **Gi·∫£i th√≠ch:** Bao g·ªìm nh·∫≠n di·ªán khu√¥n m·∫∑t, gi·ªõi t√≠nh, ƒë·ªô tu·ªïi, qu·ªëc t·ªãch v√† ƒë·∫øm ng∆∞·ªùi.\n",
      "   - **V√≠ d·ª• m·∫´u:** S·ª≠ d·ª•ng camera ƒë·ªÉ nh·∫≠n di·ªán v√† ph√¢n t√≠ch ƒë√°m ƒë√¥ng.\n",
      "\n",
      "3. **C√¥ng c·ª• Gi√°m s√°t (Grafana & Prometheus):**\n",
      "   - **T√≥m t·∫Øt:** Gi√°m s√°t tr·∫°ng th√°i h·ªá th·ªëng.\n",
      "   - **Gi·∫£i th√≠ch:** The d√µi ho·∫°t ƒë·ªông c·ªßa c√°c m√°y tr·∫°m v√† t·ªïng h·ª£p.\n",
      "   - **V√≠ d·ª• m·∫´u:** Bi·∫øn c·∫£nh b√°o t·ª´ xa qua Grafana.\n",
      "\n",
      "4. **C√¥ng c·ª• Logging (ELK Stack):**\n",
      "   - **T√≥m t·∫Øt:** Thu th·∫≠p v√† ph√¢n t√≠ch nh·∫≠t k√Ω.\n",
      "   - **Gi·∫£i th√≠ch:** S·ª≠ d·ª•ng Elasticsearch, Logstash, Kibana ƒë·ªÉ x·ª≠ l√Ω log.\n",
      "   - **V√≠ d·ª• m·∫´u:** T·∫°o b√°o c√°o t·ª´ d·ªØ li·ªáu nh·∫≠t k√Ω.\n",
      "\n",
      "5. **H·ªó tr·ª£ & B·∫£o tr√¨ (TeamViewer, AnyDesk):**\n",
      "   - **T√≥m t·∫Øt:** Qu·∫£n l√Ω v√† h·ªó tr·ª£ t·ª´ xa.\n",
      "   - **Gi·∫£i th√≠ch:** K·∫øt n·ªëi remote ƒë·ªÉ s·ª≠a l·ªói v√† c·∫≠p nh·∫≠t ph·∫ßn m·ªÅm.\n",
      "   - **V√≠ d·ª• m·∫´u:** S·ª≠ d·ª•ng TeamViewer ƒë·ªÉ truy c·∫≠p m√°y t√≠nh t·ª´ xa.\n",
      "\n",
      "6. **C·∫£nh b√°o T·ª± ƒë·ªông (Automated Alerts):**\n",
      "   - **T√≥m t·∫Øt:** C·∫£nh b√°o qua email/SMS khi c√≥ s·ª± c·ªë.\n",
      "   - **Gi·∫£i th√≠ch:** Thi·∫øt l·∫≠p h·ªá th·ªëng c·∫£nh b√°o t·ª± ƒë·ªông.\n",
      "   - **V√≠ d·ª• m·∫´u:** C·∫£nh b√°o khi camera b·ªã ng·∫Øt k·∫øt n·ªëi.\n",
      "\n",
      "7. **L∆∞u tr·ªØ D·ªØ li·ªáu (Google Cloud Storage/NAS):**\n",
      "   - **T√≥m t·∫Øt:** L∆∞u tr·ªØ video d√†i h·∫°n.\n",
      "   - **Gi·∫£i th√≠ch:** S·ª≠ d·ª•ng cloud storage ho·∫∑c NAS Synology.\n",
      "   - **V√≠ d·ª• m·∫´u:**„Éê„ÉÉ„ÇØÏóÖ video t·ª´ camera l√™n Google Cloud.\n",
      "\n",
      "8. **API v√† K·∫øt n·ªëi:**\n",
      "   - **T√≥m t·∫Øt:** T·∫°o API v√† k·∫øt n·ªëi IoT.\n",
      "   - **Gi·∫£i th√≠ch:** RESTful API v·ªõi FastAPI, WebSocket cho real-time, MQTT cho IoT.\n",
      "   - **V√≠ d·ª• m·∫´u:** K·∫øt n·ªëi camera qua MQTT ƒë·ªÉ g·ª≠i d·ªØ li·ªáu.\n",
      "\n",
      "9. **B·∫£o m·∫≠t D·ªØ li·ªáu:**\n",
      "   - **T√≥m t·∫Øt:** ƒê·∫£m b·∫£o an to√†n d·ªØ li·ªáu.\n",
      "   - **Gi·∫£i th√≠ch:** S·ª≠ d·ª•ng c√°c bi·ªán ph√°p m√£ h√≥a v√† ki·ªÉm so√°t truy c·∫≠p.\n",
      "   - **V√≠ d·ª• m·∫´u:** B·∫£o v·ªá video kh·ªèi b·ªã x√¢m ph·∫°m.\n",
      "\n",
      "10. **C·∫•u h√¨nh ƒê·∫ßu ghi NVR:**\n",
      "    - **T√≥m t·∫Øt:** C√†i ƒë·∫∑t v√† gi√°m s√°t camera t·ª´ xa.\n",
      "    - **Gi·∫£i th√≠ch:** K·∫øt n·ªëi camera, l·ªãch ghi v√† remote access.\n",
      "    - **V√≠ d·ª• m·∫´u:** Thi·∫øt l·∫≠p l·ªãch ghi video theo y√™u c·∫ßu.\n",
      "\n",
      "11. **Port Forwarding:**\n",
      "    - **T√≥m t·∫Øt:** Cho ph√©p truy c·∫≠p t·ª´ xa v√†o NVR.\n",
      "    - **Gi·∫£i th√≠ch:** C·∫•u h√¨nh router ƒë·ªÉËΩ¨Âèë port.\n",
      "    - **V√≠ d·ª• m·∫´u:** K·∫øt n·ªëi camera t·ª´ xa qua internetÂÖ¨ÁΩë.\n",
      "\n",
      "12. **M√°y Tr·∫°m v√† Aggregator (Jetson Nano & Server):**\n",
      "    - **T√≥m t·∫Øt:** X·ª≠ l√Ω d·ªØ li·ªáu v√† t·ªïng h·ª£p.\n",
      "    - **Gi·∫£i th√≠ch:** Jetson x·ª≠ l√Ω local, server t·ªïng h·ª£p data.\n",
      "    - **V√≠ d·ª• m·∫´u:** S·ª≠ d·ª•ng GPU ƒë·ªÉ tƒÉng t·ªëc x·ª≠ l√Ω video.\n",
      "\n",
      "**H·ªèi: B·∫°n c·∫ßn th√™m th√¥ng tin g√¨ v·ªÅ c√°c module n√†y kh√¥ng?**\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  b·∫°n tr·∫£ l·ªùi nh·∫ßm l·∫´n r·ªìi, c√°c d·ªãch v·ª• AI s·∫Ω tri·ªÉn khai trong ai camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I'm trying to figure out how to set up port forwarding for remote access to an NVR using Hikvision cameras. I remember that port forwarding is necessary when you want to access your NVR from outside your local network. But I'm not entirely sure about the steps involved.\n",
      "\n",
      "First, I think I need to access my router's settings. Each router has a different way of accessing its configuration page, so I'll probably have to look up how to do that for my specific model. Usually, it involves typing an IP address like 192.168.0.1 or 192.168.1.1 into a web browser.\n",
      "\n",
      "Once I'm in the router settings, I need to find where port forwarding is configured. I've heard that some routers have this under \"Advanced Settings\" or something similar. I'll look for terms like \"Port Forwarding,\" \"NAT,\" or \"Routing.\"\n",
      "\n",
      "Next, I need to know which ports to forward. From what I recall, common ports for NVRs are 80 (HTTP), 443 (HTTPS), 554 (RTSP), and maybe 8000 if the server uses that port. I should check the documentation of my Hikvision NVR to confirm which ports it's using.\n",
      "\n",
      "After identifying the correct ports, I'll set up each one individually in the router. For each port, I'll specify the external port (the same as the internal port), the protocol (TCP for most cases), and the internal IP address of my NVR. I need to make sure that the internal IP is static so it doesn't change, which means I might have to configure my network to assign a fixed IP to the NVR.\n",
      "\n",
      "I also heard about DDNS services. If my internet service provider changes my public IP frequently (which many do), using a dynamic DNS service can help because it provides a hostname that automatically updates to my current IP. Services like No-IP or Dynu offer free DDNS accounts, so I might need to set that up as well.\n",
      "\n",
      "Once port forwarding is done, I should test if remote access works. Maybe I can use an online port scanner to check if the ports are open and reachable from the internet. If it doesn't work, I'll have to troubleshoot each step: checking router settings, ensuring the NVR's IP hasn't changed, verifying that the ports are correctly forwarded.\n",
      "\n",
      "I'm a bit worried about security here. Opening up ports to the internet can expose my network to potential attacks. Maybe I should set up a strong username and password for the NVR's web interface and ensure that remote access is only allowed from specific IP addresses if possible.\n",
      "\n",
      "Also, I wonder if there are any firewalls on my router or modem that might be blocking these ports. I'll need to check those settings as well and make sure they're not interfering with the port forwarding rules.\n",
      "\n",
      "Another thing I'm unsure about is whether all the necessary ports are being forwarded correctly. If I miss a port, some features of remote access might not work, like live video streaming or accessing recorded footage. It would be helpful to have a way to test each port after setting them up.\n",
      "\n",
      "I think I should also consider using HTTPS instead of HTTP for secure communication, especially if my NVR supports it. This would encrypt the data being sent over the internet, making it more secure against eavesdroppers.\n",
      "\n",
      "Lastly, I'm not entirely clear on how to set up DDNS properly. I'll need to look up instructions specific to my router and DDNS service provider to ensure that everything is configured correctly so that remote access remains stable even with changing IPs.\n",
      "</think>\n",
      "\n",
      "To set up port forwarding for remote access to your Hikvision NVR, follow these organized steps:\n",
      "\n",
      "1. **Access Router Settings:**\n",
      "   - Open a web browser and enter your router's IP address (commonly 192.168.0.1 or 192.168.1.1) to access the configuration page.\n",
      "\n",
      "2. **Locate Port Forwarding Section:**\n",
      "   - Navigate through the router settings to find \"Port Forwarding,\" \"NAT,\" or similar options, typically under \"Advanced Settings.\"\n",
      "\n",
      "3. **Identify Required Ports:**\n",
      "   - Check your Hikvision NVR documentation to confirm which ports it uses (commonly 80, 443, 554, and possibly 8000).\n",
      "\n",
      "4. **Configure Port Forwarding:**\n",
      "   - For each port, set the external port, protocol (TCP for most cases), and internal IP address of your NVR.\n",
      "   - Ensure the NVR has a static IP to prevent changes.\n",
      "\n",
      "5. **Set Up DDNS (Optional but Recommended):**\n",
      "   - Use a DDNS service like No-IP or Dynu to handle dynamic IPs. Configure this in both your router and DDNS account settings.\n",
      "\n",
      "6. **Security Measures:**\n",
      "   - Strengthen the NVR's web interface security with a strong username/password.\n",
      "   - Consider restricting remote access to specific IP addresses if possible.\n",
      "\n",
      "7. **Firewall Configuration:**\n",
      "   - Check and configure any firewalls (router or modem) to allow the specified ports.\n",
      "\n",
      "8. **Testing:**\n",
      "   - Use an online port scanner to verify that the ports are open and reachable.\n",
      "   - Test remote access features like live streaming and recorded footage access.\n",
      "\n",
      "9. **HTTPS for Security:**\n",
      "   - If supported, configure your NVR to use HTTPS for secure communication.\n",
      "\n",
      "10. **Troubleshooting:**\n",
      "    - Recheck router settings, NVR IP, and port configurations if issues arise.\n",
      "\n",
      "By following these steps, you can securely set up remote access to your Hikvision NVR, ensuring both functionality and security.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C):  nh·ªØng module ph√¢n t√≠ch tr√™n m√°y tr·∫°m ·∫•y \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624026/302110858.py:85: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "C√¢u tr·∫£ l·ªùi: <think>\n",
      "Okay, so I'm trying to figure out what modules are on the client machine for analysis. From the context provided, it seems like there's a focus on Jetson Nano and some software tools. Let me break this down.\n",
      "\n",
      "First, the conversation history mentions \"nh·ªØng module ph√¢n t√≠ch tr√™n m√°y tr·∫°m ·∫•y.\" So, they're asking about the analysis modules on the client machine. Looking at the retrieved context, under section 2, it talks about software and analysis tools. Specifically, for Jetson Nano, there are several modules listed: face recognition, gender and age detection, counting people, and nationality recognition.\n",
      "\n",
      "Wait, so each of these is a module? Let me make sure I understand correctly. The user is asking about the modules on the client machine, which in this case is the Jetson Nano. So, the modules would be the different analysis functions it can perform.\n",
      "\n",
      "In the context, under \"Ph√¢n t√≠ch D·ªØ li·ªáu tr√™n Jetson Nano,\" they list four items: nh·∫≠n di·ªán khu√¥n m·∫∑t (face recognition), nh·∫≠n di·ªán gi·ªõi t√≠nh v√† ƒë·ªô tu·ªïi (gender and age detection), ƒë·∫øm s·ªë l∆∞·ª£ng ng∆∞·ªùi (counting people), and nh·∫≠n di·ªán qu·ªëc t·ªãch (nationality recognition). So these are the modules.\n",
      "\n",
      "I should explain each one briefly. For example, face recognition would involve detecting and identifying faces in video feeds. Gender and age detection would analyze facial features to determine those attributes. Counting people is about tracking how many individuals are present in a given area. Nationality recognition might use facial features or other data points to infer someone's nationality.\n",
      "\n",
      "I should structure the answer with a summary, explanation, examples, maybe a flowchart idea, and then a conclusion. Also, include a follow-up question to keep the conversation going.\n",
      "\n",
      "Wait, do I have enough information about each module? The context doesn't go into detail beyond listing them. So I might need to explain what each does in general terms based on standard applications of such modules.\n",
      "\n",
      "Also, considering that Jetson Nano is mentioned as being used for deep learning tasks, these modules likely involve running trained models to perform the analyses in real-time or near real-time.\n",
      "\n",
      "I should make sure the answer is clear and concise, using simple language. Maybe provide an example scenario where each module would be applied, like a security system using face recognition for access control, or a retail store using people counting for customer analytics.\n",
      "\n",
      "For the flowchart part, I can suggest that it might show data coming into the Jetson Nano, being processed by each module in sequence, and then storing the results. But since I don't have specifics on how they interact, I'll keep it general.\n",
      "\n",
      "In conclusion, these modules allow the client machine to perform various analyses useful for surveillance, customer management, etc. Then, a follow-up question could be about how these modules integrate with other systems or how data is secured.\n",
      "</think>\n",
      "\n",
      "**C√¢u tr·∫£ l·ªùi:**\n",
      "\n",
      "- **T√≥m t·∫Øt:** C√°c module ph√¢n t√≠ch tr√™n m√°y tr·∫°m Jetson Nano bao g·ªìm nh·∫≠n di·ªán khu√¥n m·∫∑t, nh·∫≠n di·ªán gi·ªõi t√≠nh v√† ƒë·ªô tu·ªïi, ƒë·∫øm s·ªë l∆∞·ª£ng ng∆∞·ªùi, v√† nh·∫≠n di·ªán qu·ªëc t·ªãch.\n",
      "\n",
      "- **Gi·∫£i th√≠ch:** M·ªói module th·ª±c hi·ªán m·ªôt ch·ª©c nƒÉng c·ª• th·ªÉ:\n",
      "  - **Nh·∫≠n di·ªán khu√¥n m·∫∑t:** Detect v√† indentify faces in video feeds.\n",
      "  - **Nh·∫≠n di·ªán gi·ªõi t√≠nh v√† ƒë·ªô tu·ªïi:** Ph√¢n t√≠ch c√°c ƒë·∫∑c ƒëi·ªÉm g∆∞∆°ng m·∫∑t ƒë·ªÉ x√°c ƒë·ªãnh gi·ªõi t√≠nh v√† ƒë·ªô tu·ªïi.\n",
      "  - **ƒê·∫øm s·ªë l∆∞·ª£ng ng∆∞·ªùi:** Theo d√µi v√† ƒë·∫øm s·ªë ng∆∞·ªùi trong m·ªôt khu v·ª±c c·ª• th·ªÉ.\n",
      "  - **Nh·∫≠n di·ªán qu·ªëc t·ªãch:** D·ª±a tr√™n d·ªØ li·ªáu g∆∞∆°ng m·∫∑t ho·∫∑c kh√°c ƒë·ªÉ infer nationality.\n",
      "\n",
      "- **V√≠ d·ª• m·∫´u:**\n",
      "  - An ninh: S·ª≠ d·ª•ng nh·∫≠n di·ªán khu√¥n m·∫∑t cho ki·ªÉm so√°t truy c·∫≠p.\n",
      "  - Qu·∫£n l√Ω b√°n l·∫ª: ƒê·∫øm s·ªë l∆∞·ª£ng ng∆∞·ªùi ƒë·ªÉ ph√¢n t√≠chÂÆ¢ÊµÅ (customer flow).\n",
      "\n",
      "- **Flowchart:** D·ªØ li·ªáu v√†o Jetson Nano ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi c√°c module theo th·ª© t·ª±, k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u tr·ªØ.\n",
      "\n",
      "- **K·∫øt lu·∫≠n:** C√°c module n√†y cho ph√©p h·ªá th·ªëng th·ª±c hi·ªán ph√¢n t√≠ch hi·ªáu qu·∫£ trong gi√°m s√°t v√† qu·∫£n l√Ω.\n",
      "\n",
      "**G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo:**\n",
      "B·∫°n mu·ªën bi·∫øt th√™m v·ªÅ c√°ch c√°c module n√†y k·∫øt n·ªëi v·ªõi h·ªá th·ªëng t·ªïng h·ª£p d·ªØ li·ªáu kh√¥ng?\n"
     ]
    }
   ],
   "source": [
    "qdrant_client = Qdrant()\n",
    "qdrant_client.create_collection(collection_name)\n",
    "qdrant_client.insert_documents(collection_name=collection_name, doc_chunks=docs, embeddings=embeddings)\n",
    "question = input(\"H√£y nh·∫≠p c√¢u h·ªèi v√†o ƒë√¢y nh√©: \")\n",
    "historys = []\n",
    "history_string = \"\\n\".join(f\"User: {chat['user']}\\nBot: {chat['bot']}\" for chat in historys)\n",
    "while True:\n",
    "    try:\n",
    "        # Ki·ªÉm tra n·∫øu ng∆∞·ªùi d√πng mu·ªën tho√°t\n",
    "        if question.lower() in [\"cancel\", \"tho√°t\", \"exit\"]:\n",
    "            print(\"ƒê√£ tho√°t ch∆∞∆°ng tr√¨nh.\")\n",
    "            break\n",
    "        \n",
    "        res = build_chain(llm, qdrant_client, collection_name=collection_name, embeddings=embeddings, question=question, history = history_string)\n",
    "        print(\"---\" * 40)\n",
    "        print(f\"C√¢u tr·∫£ l·ªùi: {res}\")\n",
    "        question = input(\"H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C): \")\n",
    "        historys.append({\n",
    "            \"user\": question,\n",
    "            \"bot\": res\n",
    "        })\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nƒê√£ tho√°t ch∆∞∆°ng tr√¨nh b·∫±ng Ctrl+C.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói: {e}\")\n",
    "        question = input(\"H√£y nh·∫≠p c√¢u h·ªèi ti·∫øp theo (ho·∫∑c nh·∫≠p 'cancel' ƒë·ªÉ tho√°t, ho·∫∑c nh·∫•n Ctrl+C): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bd6d0-e325-4d50-8d08-7521d9af7e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b966b-adbd-4a92-a1f9-2af08a067334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
