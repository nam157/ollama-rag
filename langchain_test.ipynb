{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from telegram import Update\n",
    "# from telegram.ext import Updater, CommandHandler, MessageHandler, filters, CallbackContext, ApplicationBuilder\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Enable logging\n",
    "# logging.basicConfig(\n",
    "#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "#     level=logging.INFO\n",
    "# )\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Replace 'YOUR_TELEGRAM_BOT_TOKEN' with your actual token\n",
    "# TELEGRAM_TOKEN = '7212830442:AAGldEXk5zN4Ri-fteXKugqIvXJbJ0149k0'\n",
    "# OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# # Function to generate response from Ollama\n",
    "# # def generate_response(input_text):\n",
    "# #     headers = {\"Content-Type\": \"application/json\"}\n",
    "# #     payload = {\n",
    "# #         \"prompt\": input_text,\n",
    "# #         \"model\": \"llama3\",\n",
    "# #         \"options\": {\"stream\": False}  # Set to False for synchronous response\n",
    "# #     }\n",
    "# #     try:\n",
    "# #         response = requests.post(OLLAMA_API_URL, headers=headers, data=json.dumps(payload))\n",
    "# #         response.raise_for_status()\n",
    "\n",
    "# #         # Process line-by-line JSON objects\n",
    "# #         responses = []\n",
    "# #         for line in response.text.splitlines():\n",
    "# #             try:\n",
    "# #                 data = json.loads(line)\n",
    "# #                 if 'response' in data:\n",
    "# #                     responses.append(data['response'])\n",
    "# #                 if data.get(\"done\", False):\n",
    "# #                     break\n",
    "# #             except json.JSONDecodeError as e:\n",
    "# #                 logger.error(f\"JSON decode error: {e}. Raw line: {line}\")\n",
    "\n",
    "# #         # Join all the pieces together\n",
    "# #         return ' '.join(responses) if responses else \"I am not sure how to respond.\"\n",
    "\n",
    "# #     except requests.exceptions.RequestException as e:\n",
    "# #         logger.error(f\"API request failed: {e}\")\n",
    "# #         return \"I am unable to process your request at the moment. Please try again later.\"\n",
    "# def generate_response(input_text):\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"prompt\": input_text,\n",
    "#         \"model\": \"llama3\",\n",
    "#         \"options\": {\"stream\": True}  # Stream for word-by-word response\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(OLLAMA_API_URL, headers=headers, data=json.dumps(payload))\n",
    "#         response.raise_for_status()\n",
    "\n",
    "#         responses = []\n",
    "#         for line in response.text.splitlines():\n",
    "#             try:\n",
    "#                 data = json.loads(line)\n",
    "#                 if 'response' in data:\n",
    "#                     responses.append(data['response'])\n",
    "#                 if data.get(\"done\", False):\n",
    "#                     break\n",
    "#             except json.JSONDecodeError as e:\n",
    "#                 logger.error(f\"JSON decode error: {e}. Raw line: {line}\")\n",
    "\n",
    "#         return ' '.join(responses) if responses else \"I am not sure how to respond.\"\n",
    "\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         logger.error(f\"API request failed: {e}\")\n",
    "#         return \"I am unable to process your request at the moment. Please try again later.\"\n",
    "\n",
    "\n",
    "# # Define command handlers\n",
    "# async def start(update: Update, context: CallbackContext):\n",
    "#     \"\"\"Send a welcome message when the /start command is issued.\"\"\"\n",
    "#     await update.message.reply_text('Hello! I am your AI assistant. How can I help you today?')\n",
    "\n",
    "# async def help_command(update: Update, context: CallbackContext):\n",
    "#     \"\"\"Send a message when the /help command is issued.\"\"\"\n",
    "#     await update.message.reply_text('You can ask me anything by typing your message.')\n",
    "\n",
    "# async def handle_message(update: Update, context: CallbackContext):\n",
    "#     \"\"\"Handle incoming messages from the user.\"\"\"\n",
    "#     user_message = update.message.text\n",
    "#     user_id = update.message.chat_id\n",
    "#     logger.info(f\"User ({user_id}) says: {user_message}\")\n",
    "\n",
    "#     # Generate response from Ollama\n",
    "#     try:\n",
    "#         response_text = generate_response(user_message)\n",
    "#         await update.message.reply_text(response_text)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error generating response: {e}\")\n",
    "#         await update.message.reply_text(\"Sorry, I encountered an error while processing your request.\")\n",
    "\n",
    "# async def error(update: Update, context: CallbackContext):\n",
    "#     \"\"\"Log errors caused by Updates.\"\"\"\n",
    "#     logger.error(f\"Update {update} caused error {context.error}\")\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Start the bot.\"\"\"\n",
    "#     application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "#     # Register command handlers\n",
    "#     application.add_handler(CommandHandler(\"start\", start))\n",
    "#     application.add_handler(CommandHandler(\"help\", help_command))\n",
    "\n",
    "#     # Register a message handler\n",
    "#     application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "\n",
    "#     # Log all errors\n",
    "#     application.add_error_handler(error)\n",
    "\n",
    "#     # Start the Bot\n",
    "#     application.run_polling()\n",
    "\n",
    "#     logger.info(\"Bot started. Listening for messages...\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Fetch Telegram token from environment variable\n",
    "TELEGRAM_TOKEN = '7212830442:AAGldEXk5zN4Ri-fteXKugqIvXJbJ0149k0'\n",
    "if not TELEGRAM_TOKEN:\n",
    "    logger.error(\"TELEGRAM_BOT_TOKEN not found in environment variables.\")\n",
    "    exit(1)\n",
    "\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Function to generate response from Ollama word by word\n",
    "def generate_response(input_text):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"prompt\": input_text,\n",
    "        \"model\": \"deepseek-r1:14b\",\n",
    "        \"options\": {\"stream\": True}  # Stream for word-by-word response\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "\n",
    "        responses = []\n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'response' in data:\n",
    "                    responses.append(data['response'])\n",
    "                if data.get(\"done\", False):\n",
    "                    break\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"JSON decode error: {e}. Raw line: {line}\")\n",
    "\n",
    "        return ' '.join(responses) if responses else \"I am not sure how to respond.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request failed: {e}\")\n",
    "        return \"I am unable to process your request at the moment. Please try again later.\"\n",
    "\n",
    "# Define command handlers\n",
    "async def start(update: Update, context: CallbackContext):\n",
    "    await update.message.reply_text('Hello! I am your AI assistant. How can I help you today?')\n",
    "\n",
    "async def help_command(update: Update, context: CallbackContext):\n",
    "    await update.message.reply_text('You can ask me anything by typing your message.')\n",
    "\n",
    "async def handle_message(update: Update, context: CallbackContext):\n",
    "    user_message = update.message.text\n",
    "    user_id = update.message.chat_id\n",
    "    logger.info(f\"User ({user_id}) says: {user_message}\")\n",
    "\n",
    "    # Generate response from Ollama\n",
    "    response_text = generate_response(user_message)\n",
    "    await update.message.reply_text(response_text)\n",
    "\n",
    "async def error(update: Update, context: CallbackContext):\n",
    "    logger.error(f\"Update {update} caused error {context.error}\")\n",
    "\n",
    "# Main function to run the bot\n",
    "def main():\n",
    "    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(CommandHandler(\"help\", help_command))\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "\n",
    "    application.add_error_handler(error)\n",
    "\n",
    "    application.run_polling()\n",
    "    logger.info(\"Bot started. Listening for messages...\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "import requests\n",
    "import json\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from googlesearch import search as google_search\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Telegram token\n",
    "TELEGRAM_TOKEN = '7212830442:AAGldEXk5zN4Ri-fteXKugqIvXJbJ0149k0'\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Đường dẫn tới thư mục chứa nhiều tài liệu\n",
    "DOCUMENTS_DIR = \"path_to_your_documents_folder\"\n",
    "\n",
    "# Khởi tạo embeddings và vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = None\n",
    "\n",
    "# Tải và xử lý nhiều tài liệu\n",
    "def load_and_process_documents():\n",
    "    global vector_store\n",
    "    try:\n",
    "        all_chunks = []\n",
    "        for filename in os.listdir(DOCUMENTS_DIR):\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(DOCUMENTS_DIR, filename)\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents = loader.load()\n",
    "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "                chunks = text_splitter.split_documents(documents)\n",
    "                all_chunks.extend(chunks)\n",
    "        if all_chunks:\n",
    "            vector_store = FAISS.from_documents(all_chunks, embeddings)\n",
    "            logger.info(\"Multiple documents loaded and vectorized successfully.\")\n",
    "        else:\n",
    "            logger.warning(\"No documents found in the directory.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading documents: {e}\")\n",
    "\n",
    "# Truy xuất thông tin từ tài liệu\n",
    "def retrieve_from_document(query):\n",
    "    if vector_store is None:\n",
    "        return \"Documents not loaded yet.\"\n",
    "    try:\n",
    "        docs = vector_store.similarity_search(query, k=3)\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving from documents: {e}\")\n",
    "        return \"Unable to retrieve information from the documents.\"\n",
    "\n",
    "# Tìm kiếm web\n",
    "def search_web(query):\n",
    "    try:\n",
    "        results = list(google_search(query, num_results=3))\n",
    "        return \"\\n\".join([f\"Web result: {url}\" for url in results])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Web search failed: {e}\")\n",
    "        return \"Unable to fetch web results.\"\n",
    "\n",
    "# Tìm kiếm trên X (dùng khả năng của Grok)\n",
    "def search_x(query):\n",
    "    # Giả lập tìm kiếm X bằng cách tận dụng khả năng của Grok\n",
    "    # Trong thực tế, tôi sẽ gọi API nội bộ của xAI để tìm kiếm X\n",
    "    return f\"X search results for '{query}' (simulated by Grok).\"\n",
    "\n",
    "# Tối ưu hóa prompt\n",
    "def optimize_prompt(query, retrieved_info, external_info):\n",
    "    return f\"\"\"\n",
    "    You are Grok, created by xAI. Answer the following query concisely and accurately, using the provided information if relevant. Avoid unnecessary filler and focus on delivering value.\n",
    "\n",
    "    User query: {query}\n",
    "    Retrieved from documents: {retrieved_info}\n",
    "    External info (web/X): {external_info}\n",
    "    Provide a clear, concise, and helpful response:\n",
    "    \"\"\"\n",
    "\n",
    "# Gửi yêu cầu tới Ollama với prompt tối ưu\n",
    "def generate_response_with_rag(query):\n",
    "    # Truy xuất từ tài liệu\n",
    "    retrieved_info = retrieve_from_document(query)\n",
    "    \n",
    "    # Tìm kiếm bên ngoài nếu từ khóa \"search\" hoặc \"web\" hoặc \"X\" xuất hiện\n",
    "    external_info = \"\"\n",
    "    if \"search\" in query.lower() or \"web\" in query.lower():\n",
    "        external_info = search_web(query)\n",
    "    elif \"x\" in query.lower():\n",
    "        external_info = search_x(query)\n",
    "\n",
    "    # Tối ưu hóa prompt\n",
    "    optimized_prompt = optimize_prompt(query, retrieved_info, external_info)\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"prompt\": optimized_prompt,\n",
    "        \"model\": \"deepseek-r1:14b\",\n",
    "        \"options\": {\"stream\": True}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "\n",
    "        responses = []\n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'response' in data:\n",
    "                    responses.append(data['response'])\n",
    "                if data.get(\"done\", False):\n",
    "                    break\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"JSON decode error: {e}. Raw line: {line}\")\n",
    "\n",
    "        return ' '.join(responses) if responses else \"I am not sure how to respond.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request failed: {e}\")\n",
    "        return \"I am unable to process your request at the moment. Please try again later.\"\n",
    "\n",
    "# Command handlers\n",
    "async def start(update: Update, context: CallbackContext):\n",
    "    await update.message.reply_text('Hello! I am your RAG-powered AI assistant. I can search documents, web, or X. Ask me anything!')\n",
    "\n",
    "async def help_command(update: Update, context: CallbackContext):\n",
    "    await update.message.reply_text('Ask me anything. Use \"search\", \"web\", or \"X\" to trigger external searches.')\n",
    "\n",
    "async def handle_message(update: Update, context: CallbackContext):\n",
    "    user_message = update.message.text\n",
    "    user_id = update.message.chat_id\n",
    "    logger.info(f\"User ({user_id}) says: {user_message}\")\n",
    "\n",
    "    response_text = generate_response_with_rag(user_message)\n",
    "    await update.message.reply_text(response_text)\n",
    "\n",
    "async def error(update: Update, context: CallbackContext):\n",
    "    logger.error(f\"Update {update} caused error {context.error}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Tải tài liệu khi khởi động\n",
    "    load_and_process_documents()\n",
    "\n",
    "    # Khởi động bot Telegram\n",
    "    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(CommandHandler(\"help\", help_command))\n",
    "    application.add_handler(MessageHandler(Filters.text & ~Filters.command, handle_message))\n",
    "\n",
    "    application.add_error_handler(error)\n",
    "\n",
    "    application.run_polling()\n",
    "    logger.info(\"Bot started. Listening for messages...\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
